# Документация

## Содержание <a id="toc"></a>

* [Датасет MNIST](#mnist)
* [Решаемая задача](#task)
* [Структура и параметры модели](#stracture)
* [Функция потерь](#loss_func)
* [Оптимизатор](#optimizer)
* [Планировщик скорости обучения](#sheduler)
* [Инференс модели](#infer)



## Датасет MNIST <a id="mnist"></a>

База данных MIST (Модифицированная база данных Национального института стандартов и технологий) представляет собой большую коллекцию рукописных цифр. Датасет содержит обучающий набор из 60,000 примеров и тестовый набор из 10,000 примеров. Данные представляют собой монохромные, нормализованые по размеру и центрированые изображения рукописных цифр. Каждая картинка имеет размер 28х28 пикселей (всего 784 пикселей).

## Решаемая задача <a id="task"></a>
Поставленная задача - это задача распознавания рукописных цифр. Датасет состоит из 10 различных классов в диапазоне от 0 до 9. Таким образом проблема, к которой мы собираемся подойти, - это проблема многоклассовой классификации.

## Структура и параметры модели <a id="stracture"></a>
Модель состоит из трех компонентов:
* Входной слой
* Скрытые слои (в используемой модели 4 скрытых слоя)
* Выходной слой

Для создания нейроной сети используем следующие модули PyTorch

`nn.module`  помогает нам создать искусственную нейронную сеть

`nn.Linear` обеспечивает линейную связь между функцией и нейроном

`Torch.nn.functional` модуль состоит из всех функций активации и функции вывода (eg:- relu , leaky relu , softmax ,sigmoid etc.).
Для нашей модели выберем в качестве функции активации функцию Relu, которая описывается выражением ReLU(x)=max(0,x).
![Relu image](https://neurohive.io/wp-content/uploads/2018/11/0_vGJq0cIuvTB9dvf5_.jpg)

Параметры модели:
* Размер каждой входной выборки
* Размер каждой выходной выборки
* Смещение (bias)

В используемой модели параметры имееют следующие значения:
```
input_size=784, hidden_size1=200, hidden_size2=150, hidden_size3=100,hidden_size=80, output=10, bias = True
```
## Функция потерь <a id="loss_func"></a>
Функция потерь-математический способ измерения того, насколько ошибочны ваши прогнозы.

В качестве функции потерь используем `nn.CrossEntropyLoss()`. Этот критерий вычисляет потери перекрестной энтропии между входом и целью.

Параметры функции: предсказанное значение, реальное значение лейбла.

### Пример работы
Графики функции потерь модели для тренировочных и валидационных данных
Train Loss | Valid Loss
:-------------------------:|:-------------------------:
![Train](/screenshots/Loss_train.jpg)|![Valid](/screenshots/Loss_valid.jpg)

[Математичское описание функции](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#crossentropyloss)

## Оптимизатор <a id="optimizer"></a>
Оптимизатор - это функция или алгоритм, который изменяет характеристики нейронной сети, такие как веса и скорость обучения. Таким образом, это помогает снизить общие потери и повысить точность.

`torch.optim.Adam()`-данная функция реализует алгоритм Adam, алгоритм оптимизации на основе градиентов первого порядка.

[Алгоритм Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)

Параметры функции: параметры модели, значение скорости обучения

## Планировщик скорости обучения <a id="sheduler"></a>
Планировщик скорости обучения - это определенная структура, которая регулирует скорость обучения между эпохами или итерациями по мере продвижения обучения.

`torch.optim.lr_scheduler.ReduceLROnPlateau()`- этот планировщик считывает количество показателей, и если в течение определенного количества эпох не наблюдается улучшения, скорость обучения снижается.

### Пример работы
График изменения Learning rate в процессе обучения, с использованием данного планировщика

![График Learning Rate](/screenshots/Learning_rate.jpg)

## Инференс модели  <a id="infer"></a>
Инференс модели - это класс, который загружает из файла обученную модель и делает предсказание по картинке.
