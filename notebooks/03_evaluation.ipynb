{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "PROJECT_DPATH = os.path.abspath(os.pardir)\n",
    "DATA_DPATH = os.path.join(PROJECT_DPATH, \"data\")\n",
    "\n",
    "# for pip environment\n",
    "sys.path.append(PROJECT_DPATH)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mnist_recognition.inference import Inference\n",
    "from mnist_recognition.evaluation import Evaluator\n",
    "from mnist_recognition.fgsm_attack import fgsm_attack\n",
    "from mnist_recognition.models import MlpModel\n",
    "from mnist_recognition.transforms import Invertor, AlbuAugmentation, Convertor\n",
    "from mnist_recognition.utils.fs import get_date_string\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DPATH = os.path.join(PROJECT_DPATH, \"results\", get_date_string())\n",
    "os.makedirs(SAVE_DPATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint_dpath = os.path.join(PROJECT_DPATH, \"checkpoints\")\n",
    "# model_name = \"best_valid_with_augmentations.pth\"\n",
    "model_name = \"best_valid.pth\"\n",
    "model_fpath = os.path.join(checkpoint_dpath, model_name)\n",
    "\n",
    "infer = Inference.from_file(model_fpath, device= DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка на исходной тестовой выборке "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.MNIST(\n",
    "   DATA_DPATH, train=False, transform=Invertor(), download=True\n",
    ")\n",
    "\n",
    "print(f\"Тестовая выборка содержит {len(test_data)} изображений\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator= Evaluator(infer, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluator.classification_report()\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAVE = True \n",
    "\n",
    "if _SAVE: \n",
    "    fpath = os.path.join(SAVE_DPATH, f\"source_test_evaluation_{model_name.split('.')[0]}.csv\")\n",
    "    predictions.to_csv(fpath, index_label='id')\n",
    "\n",
    "    metric_fpath = os.path.join(SAVE_DPATH, f\"source_test_classification_report_{model_name.split('.')[0]}.csv\")\n",
    "    metrics.to_csv(metric_fpath, index_label='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка на тестовой выборке c альбументациями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albu = AlbuAugmentation()\n",
    "\n",
    "test_data_with_augmentation = []\n",
    "for data in tqdm(test_data, desc=\"Test Data Processing\"):\n",
    "    img, label = data\n",
    "    img = np.array(img)\n",
    "    # adding albumentations\n",
    "    transformed_img = albu(img)\n",
    "\n",
    "    # Transform array to type PIL.Image.Image \n",
    "    transformed_img = Image.fromarray(transformed_img)\n",
    "\n",
    "    # Collect data examples\n",
    "    test_data_with_augmentation.append([transformed_img,label])\n",
    "\n",
    "print(f\"Тестовая выборка содержит {len(test_data_with_augmentation)} изображений\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator= Evaluator(infer, test_data_with_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluator.classification_report()\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAVE = True \n",
    "\n",
    "if _SAVE: \n",
    "    fpath = os.path.join(SAVE_DPATH, f\"aug_test_evaluation_{model_name.split('.')[0]}.csv\")\n",
    "    predictions.to_csv(fpath, index_label='id')\n",
    "\n",
    "    metric_fpath = os.path.join(SAVE_DPATH, f\"aug_test_classification_report_{model_name.split('.')[0]}.csv\")\n",
    "    metrics.to_csv(metric_fpath, index_label='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка на данных с атаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fgsm_attack(model, device, test_loader, epsilon ):\n",
    "    output_data=[]\n",
    "    origin_data=[]\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in tqdm(test_loader):\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data.reshape(-1, 28 * 28))\n",
    "        init_pred = output.max(1, keepdim=True)[1]# get the index of the max log-probability\n",
    "        \n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "        \n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data.reshape(-1, 28 * 28), epsilon, data_grad.reshape(-1, 28 * 28))\n",
    "\n",
    "        # Transform tensor to type PIL.Image.Image \n",
    "        perturbed_data = np.reshape(perturbed_data.cpu().detach().numpy(),(28,28))\n",
    "        perturbed_data = Image.fromarray(perturbed_data)\n",
    "\n",
    "        output_data.append([perturbed_data,target.item()])\n",
    "\n",
    "        # Collect origin data examples for visualisation \n",
    "        original_img = np.reshape(data.cpu().detach().numpy(),(28,28))\n",
    "        original_img = Image.fromarray(original_img)\n",
    "        origin_data.append([original_img,target.item()])\n",
    "\n",
    "    return output_data, origin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        Invertor(),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "# загружаем тестовую выборку\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    DATA_DPATH, train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data, \n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model = MlpModel()\n",
    "model = model.to(DEVICE)\n",
    "model.load_state_dict(torch.load(model_fpath)[\"model_state\"])\n",
    "\n",
    "eps=0.1 \n",
    "perturbed_data, origin_data = data_fgsm_attack(model, DEVICE, test_dataloader, eps)\n",
    "\n",
    "print(f\"Данные с атаками содержат {len(perturbed_data)} изображений.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(infer, perturbed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluator.classification_report()\n",
    "\n",
    "print(f'Classification report with fgsm attack eps={eps}')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAVE = True \n",
    "\n",
    "if _SAVE: \n",
    "    fpath = os.path.join(SAVE_DPATH, f\"fsgm_{eps}_test_evaluation_{model_name.split('.')[0]}.csv\")\n",
    "    predictions.to_csv(fpath, index_label='id')\n",
    "\n",
    "    metric_fpath = os.path.join(SAVE_DPATH, f\"fsgm_{eps}_test_classification_report_{model_name.split('.')[0]}.csv\")\n",
    "    metrics.to_csv(metric_fpath, index_label='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка на комбинированной выборке (атаки + альбументации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug = transforms.Compose(\n",
    "    [Invertor(), Convertor(), AlbuAugmentation(), transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "test_data_with_augmentation = torchvision.datasets.MNIST(\n",
    "   DATA_DPATH, train=False, transform= transform_aug, download=True\n",
    ")\n",
    "\n",
    "test_dataloader_aug = torch.utils.data.DataLoader(\n",
    "    dataset=test_data_with_augmentation, \n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "eps=0.05\n",
    "perturbed_data_aug, _ = data_fgsm_attack(model, DEVICE, test_dataloader_aug, eps)\n",
    "\n",
    "print(f\"Комбинированная выборка содержит {len(perturbed_data)} изображений.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(infer, perturbed_data_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluator.classification_report()\n",
    "\n",
    "print(f'Classification report with fgsm attack eps={eps}')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAVE = True \n",
    "\n",
    "if _SAVE: \n",
    "    fpath = os.path.join(SAVE_DPATH, f\"mixed_{eps}_test_evaluation_{model_name.split('.')[0]}.csv\")\n",
    "    predictions.to_csv(fpath, index_label='id')\n",
    "\n",
    "    metric_fpath = os.path.join(SAVE_DPATH, f\"mixed_{eps}_test_classification_report_{model_name.split('.')[0]}.csv\")\n",
    "    metrics.to_csv(metric_fpath, index_label='label')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c2f5a87efeacbcdc5a13c8ed7753f5a831829b2302e02892a45494710f6e461"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
