{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT=os.path.join(os.path.dirname(os.path.abspath(os.pardir)))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "from object_detection.mnist_model import MNIST\n",
    "from object_detection.fgsm_attack import fgsm_attack\n",
    "from object_detection import mnist_inference\n",
    "from object_detection import mnist_evaluation\n",
    "from object_detection.transform import Invertor\n",
    "from object_detection.mnist_augmentation import AlbuAugmentation\n",
    "from object_detection.transform import Convertor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\"batch_size\": 200}\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SAVE_DPATH = os.path.join(PROJECT_ROOT,'results','mnist_train_with_aug')\n",
    "os.makedirs(SAVE_DPATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем обученную модель\n",
    "model = MNIST()\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "MODEL_FPATH = os.path.join(PROJECT_ROOT, \"checkpoints\", \"mnist_checkpoints\", \"best_with_aug.pth\")\n",
    "model.load_state_dict(torch.load(MODEL_FPATH)[\"model_state\"])\n",
    "\n",
    "# Инициализируем инференс \n",
    "infer = mnist_inference.Inference(model, device= DEVICE)\n",
    "\n",
    "# установим модель в режим оценки. В данном случае это относится к слоям отсева\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим показатели метрик модели обученной с альбументациями на исходной тестовой выборке  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем тестовую выборку\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "   os.path.join(PROJECT_ROOT, \"mnist_content\"), train=False, transform=Invertor(), download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_evaluator = mnist_evaluation.MnistEvaluator(infer,test_data)\n",
    "\n",
    "predictions = mnist_evaluator.evaluate()\n",
    "\n",
    "_SAVE = True\n",
    "\n",
    "if _SAVE: \n",
    "    predictions.to_csv(\n",
    "        os.path.join(SAVE_DPATH,f'mnist_pred_{date.today()}.csv'),\n",
    "        index_label='id'\n",
    "    )\n",
    "\n",
    "metrics =mnist_evaluator.classification_report()\n",
    "print(f'Classification report')\n",
    "print(metrics)\n",
    "\n",
    "\n",
    "_SAVE = True\n",
    "\n",
    "if _SAVE:\n",
    "    metrics.to_csv(\n",
    "        os.path.join(SAVE_DPATH,f'classification_report_{date.today()}.csv'),\n",
    "        index_label='label'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим показатели метрик модели обученной с альбументациями на тестовой выборке с альбументациями "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug = transforms.Compose(\n",
    "            [Invertor(), Convertor(), AlbuAugmentation(), transforms.ToTensor()]\n",
    "        )\n",
    "test_data_with_augmentation = torchvision.datasets.MNIST(\n",
    "   os.path.join(PROJECT_ROOT, \"mnist_content\"), train=False, transform= transform_aug, download=True\n",
    ")\n",
    "\n",
    "\n",
    "test_dataloader_aug = torch.utils.data.DataLoader(\n",
    "    dataset=test_data_with_augmentation, \n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_evaluator_aug = mnist_evaluation.MnistEvaluator(infer,test_data_with_augmentation)\n",
    "\n",
    "_SAVE_PRED= True\n",
    "\n",
    "predictions_aug = mnist_evaluator_aug.evaluate()\n",
    "\n",
    "if _SAVE_PRED:\n",
    "    predictions_aug.to_csv(\n",
    "        os.path.join(SAVE_DPATH,f'pred_with_aug_{date.today()}.csv'),\n",
    "        index_label='id'\n",
    "    )\n",
    "\n",
    "_SAVE_METRICS=True\n",
    "\n",
    "metrics_aug =mnist_evaluator_aug.classification_report()\n",
    "\n",
    "print(f'Classification report with augmentations')\n",
    "print(metrics_aug)\n",
    "\n",
    "if _SAVE_METRICS:\n",
    "    metrics_aug.to_csv(\n",
    "        os.path.join(SAVE_DPATH,f'classification_report_with_aug_{date.today()}.csv'),\n",
    "        index_label='label'\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим показатели метрик модели обученной с альбументациями на тестовой выборке с атаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform_attack = transforms.Compose(\n",
    "    [\n",
    "        Invertor(),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "# загружаем тестовую выборку\n",
    "test_data_for_attack = torchvision.datasets.MNIST(\n",
    "    \"mnist_content\", train=False, transform=transform_attack, download=True\n",
    ")\n",
    "\n",
    "test_dataloader_for_attack=torch.utils.data.DataLoader(\n",
    "    dataset=test_data_for_attack, \n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fgsm_attack(model, device, test_loader, epsilon ):\n",
    "    output_data=[]\n",
    "    origin_data=[]\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in tqdm(test_loader):\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data.reshape(-1, 28 * 28))\n",
    "        init_pred = output.max(1, keepdim=True)[1]# get the index of the max log-probability\n",
    "        \n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "        \n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data.reshape(-1, 28 * 28), epsilon, data_grad.reshape(-1, 28 * 28))\n",
    "\n",
    "        # Transform tensor to type PIL.Image.Image \n",
    "        perturbed_data = np.reshape(perturbed_data.cpu().detach().numpy(),(28,28))\n",
    "        perturbed_data = Image.fromarray(perturbed_data)\n",
    "\n",
    "        output_data.append([perturbed_data,target.item()])\n",
    "\n",
    "        # Collect origin data examples for visualisation \n",
    "        original_img = np.reshape(data.cpu().detach().numpy(),(28,28))\n",
    "        original_img = Image.fromarray(original_img)\n",
    "        origin_data.append([original_img,target.item()])\n",
    "\n",
    "    return output_data, origin_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAVE_PRED= True\n",
    "_SAVE_METRICS=True\n",
    "eps=0.05\n",
    "\n",
    "# Getting data with fgsm attack\n",
    "print('\\n Creating perturbed data ')\n",
    "perturbed_data,_ = data_fgsm_attack(model,DEVICE,test_dataloader_for_attack,eps)\n",
    "\n",
    "mnist_evaluator_attack= mnist_evaluation.MnistEvaluator(infer,perturbed_data)\n",
    "# Getting predictions \n",
    "print('Getting predictions')\n",
    "predictions_attack = mnist_evaluator_attack.evaluate()\n",
    "# Getting metrics\n",
    "metrics_attack =mnist_evaluator_attack.classification_report()\n",
    "\n",
    "print(f'Classification report with fgsm attack eps={eps}')\n",
    "print(metrics_attack)\n",
    "\n",
    "if _SAVE_PRED:\n",
    "    predictions_attack.to_csv(\n",
    "        os.path.join(SAVE_DPATH,f'pred_eps_{eps}_{date.today()}.csv'),\n",
    "        index_label='id'\n",
    "    )\n",
    "if _SAVE_METRICS:\n",
    "    metrics_attack.to_csv(\n",
    "        os.path.join(SAVE_DPATH,f'classification_report_eps_{eps}_{date.today()}.csv'),\n",
    "        index_label='label'\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим показатели метрик модели обученной с альбументациями на тестовой выборке с атаками и с альбуметациями "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAVE_PRED= True\n",
    "_SAVE_METRICS=True\n",
    "eps=0.05\n",
    "\n",
    "# Getting data with fgsm attack\n",
    "print('\\n Creating perturbed data with aug ')\n",
    "perturbed_data_aug,_ = data_fgsm_attack(model,DEVICE,test_dataloader_aug,eps)\n",
    "\n",
    "mnist_evaluator_att_aug= mnist_evaluation.MnistEvaluator(infer,perturbed_data_aug)\n",
    "# Getting predictions \n",
    "print('Getting predictions')\n",
    "predictions_attack_aug = mnist_evaluator_att_aug.evaluate()\n",
    "# Getting metrics\n",
    "metrics_attack_aug = mnist_evaluator_att_aug.classification_report()\n",
    "\n",
    "print(f'Classification report with fgsm attack eps={eps} and aug')\n",
    "print(metrics_attack_aug)\n",
    "\n",
    "if _SAVE_PRED:\n",
    "    predictions_attack_aug.to_csv(\n",
    "        os.path.join(SAVE_DPATH,f'pred_aug_eps_{eps}_{date.today()}.csv'),\n",
    "        index_label='id'\n",
    "    )\n",
    "if _SAVE_METRICS:\n",
    "    metrics_attack_aug.to_csv(\n",
    "        os.path.join(SAVE_DPATH,f'class_report_aug_eps_{eps}_{date.today()}.csv'),\n",
    "        index_label='label'\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4937b06cff5836cad3cc2bad23f7830e7027c53db134810aa8389b0d707d2198"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
